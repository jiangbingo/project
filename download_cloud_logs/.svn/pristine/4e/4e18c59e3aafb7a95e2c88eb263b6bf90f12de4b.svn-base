# -*- encoding=utf-8 -*-
#! /usr/bin/env python
import os,sys
import requests
import subprocess
import shutil
import platform
import zipfile
import logging
import datetime,time

log = logging.getLogger(__name__)
log.setLevel(logging.INFO)
ch = logging.StreamHandler()
log.addHandler(ch)
fh = logging.FileHandler(filename="log.txt", mode="a")
log.addHandler(fh)
formatter = logging.Formatter("%(asctime)s %(levelname)s %(message)s ")
ch.setFormatter(formatter)
fh.setFormatter((formatter))

cur_dir = os.path.dirname(__file__)

#默认log解压缩目录
unzip_logs_dir = r''
# 有用logs类型扩展名
DATA_EXTS = [
        '.html',
        '.log',
        '.zip',
        ".xz"
        ]

EXCLUDE_FILES=[
'index.html',
'report.html',
'debug.log'
]

EXCLUDE_FOLDERS=[
'preparation_logs',
'reporting_portal_report'
]

WGET_PATH = os.path.abspath(os.path.join(cur_dir,'./lib','wget.exe'))
UNZIP_PATH = os.path.abspath(os.path.join(cur_dir,'./lib/','7z.exe'))
sys.path.append(WGET_PATH)
sys.path.append(UNZIP_PATH)

PROXY = "http://10.144.1.10:8080"
if 'http_proxy' not in os.environ:
    os.environ['http_proxy'] = PROXY
if 'https_proxy' not in os.environ:
    os.environ['https_proxy'] = PROXY


def open_unzip_log_windows(unzip_path):
	if unzip_path and os.path.exists(unzip_path):  #文件or 目录存在
	    if os.path.isfile(unzip_path):
	        import win32process
	        try:   # 打开外部可执行程序
	            win32process.CreateProcess(unzip_path, '',None , None , 0 ,win32process. CREATE_NO_WINDOW , None , None ,win32process.STARTUPINFO())
	        except Exception, e:
	            log.error(e)
	    else:
	        os.startfile(str(unzip_path))  # 打开目录
	else:  # 不存在的目录
	    log.warning('folder does not exists')



def delete_gap_dir(dir):
    if os.path.isdir(dir):
        for d in os.listdir(dir):
            delete_gap_dir(os.path.join(dir, d))
        if not os.listdir(dir):
          os.rmdir(dir)
    log.info("delete gap directory: {}".format(dir))


class handle(object):
    def __init__(self,url):
        self.url = url
        self.system = "windows" if  platform.system().lower()== "windows" else "linux"
        if os.path.isdir(unzip_logs_dir):
            self.logs_dir = os.path.abspath(os.path.join(unzip_logs_dir,'%s'%(time.strftime("%Y%m%d_%H.%M.%S",time.localtime(time.time())))))
            log.warning("%s is not a valid folder"%unzip_logs_dir)
        else:
            self.logs_dir = os.path.abspath(os.path.join(cur_dir,'%s'%(time.strftime("%Y%m%d_%H.%M.%S",time.localtime(time.time())))))

    def download_files(self,REP_url):
        os.makedirs(self.logs_dir, 0777)
        log.info("begin to download files from:{}".format(self.url))
        # todo:https://stackoverflow.com/questions/3430810/wget-download-with-multiple-simultaneous-connections
        # options = "--tries=5 --accept {} --ignore-case -m -p -E -k -K -c -r -np -L -P".format(','.join(DATA_EXTS))
        # options = "--tries=5 -m -p -E -k -K -c -r -np -L -P"
        """
        wget options:
        -nc : "no clobber" - it causes wget to ignore aready downloaded (even partially) files. 
        """
        options = '--tries=5 --accept {} --reject-regex preparation_logs --execute robots=off -c -r -nc -np -L -P'.format(','.join(DATA_EXTS))
        log.info("begin to download files to:{}".format(self.logs_dir))
        if self.system == "windows":
            cmd = r"%s %s %s %s"%(WGET_PATH,options,self.logs_dir,self.url)
        else:
            cmd = 'wget %s %s %s'%(options,self.logs_dir,self.url)   
        subprocess.call(cmd,shell=True)

    def get_files(self):
        all_files = []
        for root, dirname, files in os.walk(self.logs_dir):
            # print dirname
            for d in dirname:
                if d in EXCLUDE_FOLDERS:
                    if os.path.exists(os.path.join(root,d)):
                        shutil.rmtree(os.path.join(root,d))
                        continue
            for f in files:
                if f in EXCLUDE_FILES:
                    os.remove(os.path.join(root,f))
                    continue
                if os.path.splitext(f)[-1] in DATA_EXTS:
                    # yield os.path.join(root, f)
                    all_files.append(os.path.join(root,f))
                if os.path.splitext(f)[-1].lower() =='.zip':
                    self.unzip(os.path.join(root,f),self.logs_dir)
                    shutil.rmtree(os.path.dirname(os.path.join(root,f)),ignore_errors=True)
                if f == "log.html":
                    shutil.move(os.path.join(root,f),self.logs_dir)
                # if len(os.listdir(root)) == 0: #check whether the directory is now empty after deletions, and if so, remove it
                #     os.rmdir(dir)
        delete_gap_dir(self.logs_dir)
        print("files are : {}".format(all_files))


    def unzip(self,zippath,dest_dir):
        if self.system == "windows":
            log.info("log dir is {}".format(dest_dir))
            options = "x -y -o{}".format(dest_dir)
            cmd = r"%s %s %s"%(UNZIP_PATH,options,zippath)
        else:
            options = "x -y -o{}".format(dest_dir)
            cmd = 'unzip %s %s'%(options,zippath)   
        subprocess.call(cmd,shell=True)

    def handle_logs(self):
        try:
            self.download_files(self.url)
            self.get_files()
        except Exception as err:
            log.error(err)
        finally:
            open_unzip_log_windows(self.logs_dir)

if __name__ == "__main__":

    REP_url = "http://logs.ute.nsn-rdnet.net/cloud/execution/4208356/"
    obj = handle(REP_url)
    obj.handle_logs()